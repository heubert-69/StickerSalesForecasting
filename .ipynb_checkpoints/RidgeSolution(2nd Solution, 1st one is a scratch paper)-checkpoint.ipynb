{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92bca02b-24b9-45dd-9792-26ad539fc1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voltsy/.local/lib/python3.12/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "2025-06-04 07:45:38.002078: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748994338.428011    2223 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748994338.537497    2223 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748994339.441522    2223 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748994339.441574    2223 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748994339.441576    2223 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748994339.441578    2223 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-04 07:45:39.549459: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "import seaborn as sns\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import holidays\n",
    "import datetime\n",
    "import wbdata\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeb4d467-88c0-43a2-a854-6e7bf6b58b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Holographic Goose</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle Tiers</td>\n",
       "      <td>906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler</td>\n",
       "      <td>423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler Dark Mode</td>\n",
       "      <td>491.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230125</th>\n",
       "      <td>230125</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Holographic Goose</td>\n",
       "      <td>466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230126</th>\n",
       "      <td>230126</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>2907.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230127</th>\n",
       "      <td>230127</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kaggle Tiers</td>\n",
       "      <td>2299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230128</th>\n",
       "      <td>230128</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kerneler</td>\n",
       "      <td>1242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230129</th>\n",
       "      <td>230129</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kerneler Dark Mode</td>\n",
       "      <td>1622.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230130 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id       date    country                 store  \\\n",
       "0            0 2010-01-01     Canada     Discount Stickers   \n",
       "1            1 2010-01-01     Canada     Discount Stickers   \n",
       "2            2 2010-01-01     Canada     Discount Stickers   \n",
       "3            3 2010-01-01     Canada     Discount Stickers   \n",
       "4            4 2010-01-01     Canada     Discount Stickers   \n",
       "...        ...        ...        ...                   ...   \n",
       "230125  230125 2016-12-31  Singapore  Premium Sticker Mart   \n",
       "230126  230126 2016-12-31  Singapore  Premium Sticker Mart   \n",
       "230127  230127 2016-12-31  Singapore  Premium Sticker Mart   \n",
       "230128  230128 2016-12-31  Singapore  Premium Sticker Mart   \n",
       "230129  230129 2016-12-31  Singapore  Premium Sticker Mart   \n",
       "\n",
       "                   product  num_sold  \n",
       "0        Holographic Goose       NaN  \n",
       "1                   Kaggle     973.0  \n",
       "2             Kaggle Tiers     906.0  \n",
       "3                 Kerneler     423.0  \n",
       "4       Kerneler Dark Mode     491.0  \n",
       "...                    ...       ...  \n",
       "230125   Holographic Goose     466.0  \n",
       "230126              Kaggle    2907.0  \n",
       "230127        Kaggle Tiers    2299.0  \n",
       "230128            Kerneler    1242.0  \n",
       "230129  Kerneler Dark Mode    1622.0  \n",
       "\n",
       "[230130 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train[\"date\"] = pd.to_datetime(train[\"date\"])\n",
    "test[\"date\"] = pd.to_datetime(test[\"date\"])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2cf243a-89ec-4888-9656-4172b2777835",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2223/4101850611.py:74: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  econ_data = pd.concat(econ_frames).reset_index()\n"
     ]
    }
   ],
   "source": [
    "#Now we do feature engineering on the test set and training set\n",
    "# Function to check if a date is a holiday for that country\n",
    "def is_holiday(row):\n",
    "    try:\n",
    "        country_code = row['country']  # make sure this matches ISO format like 'PH', 'US', etc.\n",
    "        date = row['date']\n",
    "        return date in holidays.country_holidays(country_code)\n",
    "    except:\n",
    "        return False  # if country is invalid, default to False\n",
    "\n",
    "# --- Economic indicators to fetch ---\n",
    "indicators = {\n",
    "    'NY.GDP.MKTP.CD': 'gdp',\n",
    "    'SL.UEM.TOTL.ZS': 'unemployment',\n",
    "    'FP.CPI.TOTL.ZG': 'inflation',\n",
    "    'FR.INR.LEND': 'interest_rate'\n",
    "}\n",
    "\n",
    "# --- Get country codes ---\n",
    "def get_country_code(name):\n",
    "    try:\n",
    "        return pycountry.countries.lookup(name).alpha_3\n",
    "    except LookupError:\n",
    "        return None\n",
    "\n",
    "test['num_sold'] = np.nan\n",
    "combined = pd.concat([train, test], sort=False)\n",
    "combined.sort_values(by=['country', 'store', 'product', 'date'], inplace=True)\n",
    "\n",
    "# Step 2: Feature Engineering (same as before)\n",
    "combined['month'] = combined['date'].dt.to_period('M').dt.to_timestamp()\n",
    "combined['day_of_week'] = combined[\"date\"].dt.dayofweek.astype(np.int8)\n",
    "combined['day'] = combined[\"date\"].dt.day.astype(np.int8)\n",
    "combined['year'] = combined[\"date\"].dt.year.astype(np.int16)\n",
    "combined['is_weekend'] = combined['day_of_week'].isin([5, 6]).astype(np.int8)\n",
    "combined['weekofyear'] = combined[\"date\"].dt.isocalendar().week.astype(np.int8)\n",
    "\n",
    "# --- Holiday Feature ---\n",
    "combined['is_holiday'] = combined.apply(is_holiday, axis=1).astype(np.int8)\n",
    "\n",
    "# --- Lag Features ---\n",
    "for lag in [1, 7]:\n",
    "    combined[f'lag_{lag}'] = combined.groupby(['country', 'store', 'product'])['num_sold'].shift(lag)\n",
    "\n",
    "# --- Rolling Mean ---\n",
    "combined['rolling_7'] = (\n",
    "    combined.groupby(['country', 'store', 'product'])['num_sold']\n",
    "    .shift(1)\n",
    "    .rolling(window=7, min_periods=1)\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# --- World Bank Economic Data ---\n",
    "# Fetch World Bank data (note: data is annual)\n",
    "combined['country_code'] = combined['country'].apply(get_country_code)\n",
    "countries = combined['country_code'].dropna().unique().tolist()\n",
    "\n",
    "min_year = combined['month'].min().year\n",
    "max_year = combined['month'].max().year\n",
    "start_date = datetime.datetime(min_year, 1, 1)\n",
    "end_date = datetime.datetime(max_year, 12, 31)\n",
    "\n",
    "econ_frames = []\n",
    "for country in countries:\n",
    "    df = wbdata.get_dataframe(\n",
    "        indicators,\n",
    "        country=country,\n",
    "        date=(start_date, end_date),  \n",
    "    )\n",
    "    df['country'] = country\n",
    "    econ_frames.append(df)\n",
    "\n",
    "# Combine all country data\n",
    "econ_data = pd.concat(econ_frames).reset_index()\n",
    "\n",
    "# Fix column names and extract 'month' and 'country_code'\n",
    "econ_data.rename(columns={'date': 'month', 'country': 'econ_country'}, inplace=True)\n",
    "econ_data['month'] = pd.to_datetime(econ_data['month']).dt.to_period('M').dt.to_timestamp()\n",
    "econ_data['country_code'] = econ_data['econ_country']\n",
    "combined = combined.merge(econ_data, how='left', on=['country_code', 'month'])\n",
    "\n",
    "# --- Momentum Feature ---\n",
    "combined['sales_momentum'] = (combined['lag_1'] - combined['rolling_7']) / (combined['rolling_7'] + 1e-5)\n",
    "\n",
    "\n",
    "\n",
    "required_cols = ['country', 'store', 'product', 'num_sold']\n",
    "missing = [col for col in required_cols if col not in combined.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing columns in `combined`: {missing}\")\n",
    "assert 'country' in combined.columns, \"country column missing before merge\"\n",
    "combined = combined.merge(econ_data, how='left', on=['country_code', 'month'])\n",
    "assert 'country' in combined.columns, \"country column missing after merge\"\n",
    "# --- Expanding Mean ---\n",
    "combined['expanding_mean'] = (\n",
    "    combined.groupby(['country', 'store', 'product'])['num_sold']\n",
    "    .transform(lambda x: x.shift(1).expanding(min_periods=1).mean())\n",
    ")\n",
    "\n",
    "label_encoders = {}\n",
    "for col in ['country', 'store', 'product']:\n",
    "    le = LabelEncoder()\n",
    "    combined[col] = le.fit_transform(combined[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# --- Categorical Encoding (use existing encoders) ---\n",
    "def safe_label_encode(series, le):\n",
    "    mapping = {cls: i for i, cls in enumerate(le.classes_)}\n",
    "    return series.map(lambda x: mapping.get(x, -1)).astype(int)\n",
    "\n",
    "for col in ['country', 'store', 'product']:\n",
    "    le = label_encoders[col]\n",
    "    combined[col] = safe_label_encode(combined[col], le)\n",
    "\n",
    "# --- Sales Difference & Growth ---\n",
    "combined['sales_diff'] = combined['lag_1'] - combined['lag_7']\n",
    "combined['sales_growth'] = combined['lag_1'] / (combined['lag_7'] + 1e-5)\n",
    "\n",
    "\n",
    "# --- Combined Categorical Features ---\n",
    "combined['country_product'] = (combined['country'].astype(str) + '_' + combined['product'].astype(str)).astype('category').cat.codes\n",
    "combined['store_product'] = (combined['store'].astype(str) + '_' + combined['product'].astype(str)).astype('category').cat.codes\n",
    "combined['country_store'] = (combined['country'].astype(str) + '_' + combined['store'].astype(str)).astype('category').cat.codes\n",
    "\n",
    "# --- Time Encoding (Cyclic) ---\n",
    "combined['month_sin'] = np.sin(2 * np.pi * combined['month'].dt.month / 12)\n",
    "combined['month_cos'] = np.cos(2 * np.pi * combined['month'].dt.month / 12)\n",
    "combined['day_of_week_sin'] = np.sin(2 * np.pi * combined['day_of_week'] / 7)\n",
    "combined['day_of_week_cos'] = np.cos(2 * np.pi * combined['day_of_week'] / 7)\n",
    "\n",
    "# --- Final Cleanup ---\n",
    "combined.drop(columns=[\"date_x\", \"date_y\"], inplace=True, errors='ignore')\n",
    "combined.fillna(0, inplace=True)\n",
    "\n",
    "# --- Downcast to save memory ---\n",
    "for col in combined.select_dtypes(include=['float64']).columns:\n",
    "    combined[col] = pd.to_numeric(combined[col], downcast='float')\n",
    "for col in combined.select_dtypes(include=['int64']).columns:\n",
    "    combined[col] = pd.to_numeric(combined[col], downcast='integer')\n",
    "\n",
    "combined.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99ae74f1-80fe-4b39-ac05-dbd2658649ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting it for pretraining\n",
    "X = combined.loc[combined.index.isin(train.index)].copy()\n",
    "y = train.loc[X.index, 'num_sold'].fillna(0)  # Make sure indices align\n",
    "\n",
    "# Drop target from features\n",
    "X_final = X.drop(columns=['num_sold'])\n",
    "\n",
    "# Split into train and validation sets (e.g., 80/20 split)\n",
    "X_train_final, X_val_final, y_train, y_val = train_test_split(\n",
    "    X_final, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d773b59-23bc-4941-89df-f1c98d132464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to do the machine learning\n",
    "month_transformer = FunctionTransformer(lambda x: x.astype('int64').values.reshape(-1, 1))\n",
    "\n",
    "# Use the correct dataset without the target column\n",
    "numeric_cols = X_train_final.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X_train_final.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Remove 'month' from numeric if present\n",
    "if 'month' in numeric_cols:\n",
    "    numeric_cols.remove('month')\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy='mean')),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), numeric_cols),\n",
    "    \n",
    "    (\"month\", Pipeline([\n",
    "        (\"month_int\", month_transformer),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), ['month']),\n",
    "    \n",
    "    (\"cat\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), categorical_cols)\n",
    "])\n",
    "\n",
    "ridge_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"ridge\", Ridge())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50142c3a-6a40-4d36-9e91-f7d9ccda897c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 100.0\n",
      "Validation RMSE: 692.6372\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    \"ridge__alpha\": [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(ridge_pipeline, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "X_train_final[categorical_cols] = X_train_final[categorical_cols].astype(str)\n",
    "X_test_final[categorical_cols] = X_test_final[categorical_cols].astype(str)\n",
    "search.fit(X_train_final, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = search.best_estimator_\n",
    "y_pred = best_model.predict(X_val_final)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "print(f\"Best Alpha: {search.best_params_['ridge__alpha']}\")\n",
    "print(f\"Validation RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39e420fc-3a93-4e37-a0a0-2f83ffafac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = best_model.predict(X_test_final)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],            # Use 'id' from test, not 'date'\n",
    "    'num_sold': test_preds.round().astype(int)  # Round predictions before converting to int\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7ab8a61-755c-4271-a1dd-4b81d1946d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Final File\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
