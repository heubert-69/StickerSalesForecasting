{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1bf411-d62f-47d6-8c6d-bddf9002b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "import seaborn as sns\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import holidays\n",
    "import datetime\n",
    "import wbdata\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805fe56-023a-4d7b-910c-dd7ad855cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train[\"date\"] = pd.to_datetime(train[\"date\"])\n",
    "test[\"date\"] = pd.to_datetime(test[\"date\"])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b306bf-544e-42c3-9834-ea2e507386a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a2199f-0770-468a-92cf-d479ca36ba3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292cc25-152d-4894-8fee-bde2eb70faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727baeae-7c9f-48ae-a384-298cc4095bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e514ae15-51bf-4e83-b385-0c5fde923515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering\n",
    "train['month'] = train['date'].dt.to_period('M').dt.to_timestamp()\n",
    "test['month'] = test['date'].dt.to_period('M').dt.to_timestamp()\n",
    "train['day_of_week'] = train[\"date\"].dt.dayofweek\n",
    "train['day'] = train[\"date\"].dt.day\n",
    "train['year'] = train[\"date\"].dt.year\n",
    "train['is_weekend'] = train['day_of_week'].isin([5, 6])\n",
    "train['weekofyear'] = train[\"date\"].dt.isocalendar().week\n",
    "\n",
    "# Function to check if a date is a holiday for that country\n",
    "def is_holiday(row):\n",
    "    try:\n",
    "        country_code = row['country']  # make sure this matches ISO format like 'PH', 'US', etc.\n",
    "        date = row['date']\n",
    "        return date in holidays.country_holidays(country_code)\n",
    "    except:\n",
    "        return False  # if country is invalid, default to False\n",
    "\n",
    "# Apply function row-wise\n",
    "train['is_holiday'] = train.apply(is_holiday, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51175502-9a05-4d0f-aac7-a87572be433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b9cf8-5e1f-4168-8bca-91ffe67a8057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Economic indicators to fetch\n",
    "# Define indicators\n",
    "indicators = {\n",
    "    'NY.GDP.MKTP.CD': 'gdp',                     # GDP (in dollars)\n",
    "    'SL.UEM.TOTL.ZS': 'unemployment',            # Unemployment rate (%)\n",
    "    'FP.CPI.TOTL.ZG': 'inflation',               # CPI Inflation (%)\n",
    "    'FR.INR.LEND': 'interest_rate'               # Lending interest rate (%)\n",
    "}\n",
    "\n",
    "# Get country list\n",
    "countries = train['country'].unique().tolist()\n",
    "def get_country_code(name):\n",
    "    try:\n",
    "        return pycountry.countries.lookup(name).alpha_3\n",
    "    except LookupError:\n",
    "        return None  # Or handle missing countries as you like\n",
    "\n",
    "# Example: Map the country names in your DataFrame\n",
    "train['country_code'] = train['country'].apply(get_country_code)\n",
    "\n",
    "# Now you can get the unique codes\n",
    "countries = train['country_code'].dropna().unique().tolist()\n",
    "\n",
    "\n",
    "# Define date range (wbdata is yearly, not monthly!)\n",
    "min_year = train['month'].min().year\n",
    "max_year = train['month'].max().year\n",
    "start_date = datetime.datetime(min_year, 1, 1)\n",
    "end_date = datetime.datetime(max_year, 12, 31)\n",
    "\n",
    "# Fetch World Bank data (note: data is annual)\n",
    "econ_frames = []\n",
    "for country in countries:\n",
    "    df = wbdata.get_dataframe(\n",
    "        indicators,\n",
    "        country=country,\n",
    "        date=(start_date, end_date),  \n",
    "    )\n",
    "    df['country'] = country\n",
    "    econ_frames.append(df)\n",
    "\n",
    "# Combine all country data\n",
    "econ_data = pd.concat(econ_frames).reset_index()\n",
    "\n",
    "# Format and align\n",
    "econ_data['date'] = pd.to_datetime(econ_data['date'], errors='coerce')\n",
    "econ_data['month'] = econ_data['date'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "# Merge with train and test\n",
    "train = train.merge(econ_data, how='left', on=['country', 'month'])\n",
    "test = test.merge(econ_data, how='left', on=['country', 'month'])\n",
    "\n",
    "#dropping the date_x by renaming it with date\n",
    "train[\"date\"] = train[\"date_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609d739-24d6-4134-91e3-89cc0cf143ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060926f-ce71-41dd-850d-58774d8ce7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['month'] = train[\"date\"].dt.month\n",
    "train['day'] = train[\"date\"].dt.day\n",
    "train['weekday'] = train[\"date\"].dt.weekday\n",
    "train['weekofyear'] = train[\"date\"].dt.isocalendar().week.astype(int)\n",
    "train['is_weekend'] = train['weekday'].isin([5, 6]).astype(int)\n",
    "train['quarter'] = train[\"date\"].dt.quarter\n",
    "\n",
    "for lag in [1, 2, 3, 7, 14, 28]:\n",
    "    train[f'lag_{lag}'] = train.groupby(['country', 'store', 'product'])['num_sold'].shift(lag)\n",
    "\n",
    "# --- Rolling Mean & Std Features ---\n",
    "train['rolling_7'] = train.groupby(['country', 'store', 'product'])['num_sold'].shift(1).rolling(window=7).mean()\n",
    "train['rolling_30'] = train['num_sold'].rolling(30).mean()\n",
    "train['rolling_14'] = train.groupby(['country', 'store', 'product'])['num_sold'].shift(1).rolling(window=14).mean()\n",
    "train['rolling_std_7'] = train.groupby(['country', 'store', 'product'])['num_sold'].shift(1).rolling(window=7).std()\n",
    "\n",
    "# --- Expanding Mean ---\n",
    "train['expanding_mean'] = train.groupby(['country', 'store', 'product'])['num_sold'].transform(lambda x: x.shift(1).expanding().mean())\n",
    "\n",
    "# --- Sales Dynamics ---\n",
    "train['sales_diff'] = train['lag_1'] - train['lag_2']\n",
    "train['sales_growth'] = train['lag_1'] / (train['lag_2'] + 1e-5)\n",
    "\n",
    "# --- Categorical Encoding (LabelEncoder for XGBoost) ---\n",
    "label_encoders = {}\n",
    "for col in ['country', 'store', 'product']:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    label_encoders[col] = le  # keep if you want to decode later\n",
    "\n",
    "# --- Interaction Features ---\n",
    "train['country_product'] = train['country'].astype(str) + '_' + train['product'].astype(str)\n",
    "train['store_product'] = train['store'].astype(str) + '_' + train['product'].astype(str)\n",
    "train['country_store'] = train['country'].astype(str) + '_' + train['store'].astype(str)\n",
    "\n",
    "for col in ['country_product', 'store_product', 'country_store']:\n",
    "    train[col] = LabelEncoder().fit_transform(train[col])\n",
    "\n",
    "#filling na values\n",
    "train = train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9463def-713b-428f-ae3b-a4d8e1d4ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da40d3-0469-4c43-bb6b-089e573b6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"num_sold\"].plot(figsize=(20, 5), title=\"Sales over time\")\n",
    "#plt.savefig(\"Sales Over Time.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58d34e-df82-4846-99f9-1d4d74b082ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelation_plot(train[\"num_sold\"])\n",
    "#plt.title(\"Correlation between Past Values\")\n",
    "#plt.savefig(\"Evidence of Past Values affecting the future.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ec264-ca9c-4fc3-af81-44cd30d431fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=train['is_holiday'], y=train['num_sold'], data=train.reset_index())\n",
    "#plt.savefig(\"Impact of Sales on Holidays vs Holidays\")\n",
    "plt.title(\"Sales on Holidays vs Non-Holidays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c855a-0e0f-45ec-aa97-1868d2670a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average sales by month\n",
    "sns.barplot(x=train['month'], y=train['num_sold'], data=train.reset_index())\n",
    "#plt.savefig(\"Average Monthly Sales.png\")\n",
    "plt.title(\"Avg Monthly Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c204989f-97ba-47ad-af91-598fdd3f892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day-of-week visualization\n",
    "sns.barplot(x=train['day_of_week'], y=train['num_sold'], data=train.reset_index())\n",
    "#plt.savefig(\"Average Sales by Day of The Week.png\")\n",
    "plt.title(\"Avg Sales by Day of Week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f463b2c-69cb-4cd6-b91b-af05f75e2a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Economic Relationship\n",
    "sns.heatmap(train[['num_sold', 'gdp', 'inflation', 'interest_rate']].corr(), annot=True)\n",
    "#plt.savefig(\"Economic Relationships.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d99b2f3-5fc4-4368-a11f-69ae01e0f16d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[['num_sold', 'rolling_7', 'rolling_30']].plot(figsize=(15,5), title=\"Sales with Rolling Means\")\n",
    "#plt.savefig(\"Number of Goods Sold with Rolling Means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68df596-2791-4596-b2f0-eb516a391f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building\n",
    "X = train[[i for i in train.columns if i not in [\"num_sold\", \"date_x\", \"country\"]]]\n",
    "y = train[\"num_sold\"]\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d4fc7e-ef21-4c43-b52c-4dd54309c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectors\n",
    "num_selector = make_column_selector(dtype_include=np.number)\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_selector)\n",
    "])\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('scaler', preprocessor),\n",
    "    ('xgb', XGBRegressor(objective='reg:squarederror', random_state=42))\n",
    "])\n",
    "\n",
    "# Parameter grid\n",
    "xgb_param_grid = {\n",
    "    'xgb__n_estimators': [100, 200],\n",
    "    'xgb__max_depth': [3, 5],\n",
    "    'xgb__learning_rate': [0.01, 0.1],\n",
    "    'xgb__subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "xgb_grid = GridSearchCV(xgb_pipeline, xgb_param_grid, cv=5,\n",
    "                        scoring='neg_mean_squared_error',\n",
    "                        n_jobs=-1, verbose=1, error_score='raise')\n",
    "xgb_grid.fit(X_train, Y_train)\n",
    "\n",
    "# Results\n",
    "print(\"Best XGB Params:\", xgb_grid.best_params_)\n",
    "print(\"Best XGB Score (CV MSE):\", -xgb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a08626-de73-4c2e-9b4c-dc581bf3bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for the best parameters for my ridge regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2c1d72-6f14-4bec-bbbe-24d93f018c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
